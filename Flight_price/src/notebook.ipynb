{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries\r\n",
    "import pandas as pd \r\n",
    "import numpy as np \r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import seaborn as sns\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\r\n",
    "from datetime import datetime as dt\r\n",
    "from sklearn.metrics import mean_squared_error, r2_score\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.model_selection import train_test_split as TTS, KFold as K, cross_val_score as score  \r\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\r\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR \r\n",
    "from xgboost import XGBRegressor as XGR\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\r\n",
    "\r\n",
    "import pickle\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the datset\r\n",
    "df = pd.read_csv(r'../Data/flight_price.csv')\r\n",
    "target=df.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class filters(BaseEstimator,TransformerMixin):\r\n",
    "    def __init__(self, Total_Stops):\r\n",
    "        self.Total_Stops=Total_Stops\r\n",
    "\r\n",
    "    def fit(self,X,y=None):\r\n",
    "        return self\r\n",
    "\r\n",
    "    def transform(self, X, y=None):\r\n",
    "\r\n",
    "        non_stop={'non-stop':1, np.nan:1, '2 stops':0, '1 stop':0, '3 stops':0,'4 stops':0}\r\n",
    "        X.Total_Stops = X.Total_Stops.map(non_stop)\r\n",
    "        \r\n",
    "        X = X[X.Total_Stops==1]\r\n",
    "\r\n",
    "        return X.values\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline([('filter_hopping_flights', filters('Total_Stops'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "op=pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3492, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(op).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10683, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks:\r\n",
    "\r\n",
    "1. Airline -> OneHotEncoder() `DONE`\r\n",
    "2. Date_of_Journey -> Month of year, Day of month, day of week, day of year  `DONE`\r\n",
    "3. Source and Destination -> Route  `DONE`  \r\n",
    "4. Drop Route, Arrival_Time, Total_Stops\r\n",
    "5. Dep_Time -> Extract hour and min `DONE`\r\n",
    "6. Dep hour -> Time of day\r\n",
    "7. Duration -> Duration hour, duration minutes `DONE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Additional_Info','Arrival_Time','Route'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Dep_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.Date_of_Journey[0])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models(model):\r\n",
    "\r\n",
    "    folds=K(n_splits=5, shuffle=True, random_state=4)\r\n",
    "    r=score(model,X,y,scoring='neg_mean_squared_error',cv=folds)\r\n",
    "    scores = str(-round(np.sqrt(r.mean()),2))+\" Â± \"+str(round(np.sqrt(r.std()),2))\r\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d=DTR(max_depth=14)\n",
    "r=RFR(max_depth=16, random_state=123456)\n",
    "x=XGR(max_depth=5,eta=0.5, subsample=0.92)\n",
    "print(\"Absolute error for Decision tree regressor\",models(d))    #Median best max_depth after 100 iterations of cross validation\n",
    "print(\"Absolute error for Random forest regressor\",models(r))\n",
    "print(\"Absolute error for XGB Regressor\",models(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=DTR(max_depth=16)\n",
    "rr.fit(X,y)\n",
    "pd.DataFrame(rr.feature_importances_*100,index=X.columns).sort_values(0,ascending=False).style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "hours_calc=df[['Airline','Source','Destination','Duration_hours','Duration_mins']]\r\n",
    "hours_calc=hours_calc[hours_calc.Airline.isin(['IndiGo','Air India','SpiceJet','Air Asia','GoAir','Vistara'])]\r\n",
    "hours_calc=hours_calc.groupby(['Airline','Source','Destination'])[['Duration_hours','Duration_mins']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours_calc.to_csv(r\"../deployment/hour_calculation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..\\deployment\\model','wb') as f:\n",
    "    pickle.dump(r,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "62a490a61034db1e8b6e05e6e999b5629625384177f9d8186b44b788547d5428"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('machine_L': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "6beebaa0981c1e9d17bebb217d7d2d19f8163b6f1d7ac3bbe835b659c5d6023d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}